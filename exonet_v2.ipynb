{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJqG1C0QxACpa22/+Ufk6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhara/new_world_disco/blob/main/exonet_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aTTRiZZpyOic"
      },
      "outputs": [],
      "source": [
        "\n",
        "########################################\n",
        "########### IMPORT PACKAGES ############\n",
        "########################################\n",
        "\n",
        "### standard packages\n",
        "import os\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "from tqdm import tqdm\n",
        "from random import random\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import pdb\n",
        "\n",
        "### torch packages\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "\n",
        "### sklearn packages\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "### plotting packages\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "########################################\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "########### DEFINE CLASSES  ############\n",
        "########################################\n",
        "\n",
        "class KeplerDataLoader(Dataset):\n",
        "\n",
        "    '''\n",
        "    PURPOSE: DATA LOADER FOR KERPLER LIGHT CURVES\n",
        "    INPUT: PATH TO DIRECTOR WITH LIGHT CURVES + INFO FILES\n",
        "    OUTPUT: LOCAL + GLOBAL VIEWS, LABELS\n",
        "    '''\n",
        "\n",
        "    def __init__(self, filepath):\n",
        "\n",
        "        ### list of global, local, and info files (assumes certain names of files)\n",
        "        self.flist_global = np.sort(glob.glob(os.path.join(filepath, '*global.npy')))\n",
        "        self.flist_local = np.sort(glob.glob(os.path.join(filepath, '*local.npy')))\n",
        "        self.flist_info = np.sort(glob.glob(os.path.join(filepath, '*info.npy')))\n",
        "\n",
        "        ### list of whitened centroid files\n",
        "        self.flist_global_cen = np.sort(glob.glob(os.path.join(filepath, '*global_cen_w.npy')))\n",
        "        self.flist_local_cen = np.sort(glob.glob(os.path.join(filepath, '*local_cen_w.npy')))\n",
        "\n",
        "        ### ids = {TIC}_{TCE}\n",
        "        self.ids = np.sort([(x.split('/')[-1]).split('_')[1] + '_' + (x.split('/')[-1]).split('_')[2] for x in self.flist_global])\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return self.ids.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        ### grab local and global views\n",
        "        data_global = np.load(self.flist_global[idx])\n",
        "        data_local = np.load(self.flist_local[idx])\n",
        "\n",
        "        ### grab centroid views\n",
        "        data_global_cen = np.load(self.flist_global_cen[idx])\n",
        "        data_local_cen = np.load(self.flist_local_cen[idx])\n",
        "\n",
        "        ### info file contains: [0]kic, [1]tce, [2]period, [3]epoch, [4]duration, [5]label)\n",
        "        data_info = np.load(self.flist_info[idx])\n",
        "\n",
        "        return (data_local, data_global, data_local_cen, data_global_cen, data_info[6:]), data_info[5]\n"
      ],
      "metadata": {
        "id": "k619IXKW0bC1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtranetModel(nn.Module):\n",
        "\n",
        "    '''\n",
        "\n",
        "    PURPOSE: DEFINE EXTRANET MODEL ARCHITECTURE\n",
        "    INPUT: GLOBAL + LOCAL LIGHT CURVES AND CENTROID CURVES, STELLAR PARAMETERS\n",
        "    OUTPUT: BINARY CLASSIFIER\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        ### initialize model\n",
        "        super(ExtranetModel, self).__init__()\n",
        "\n",
        "        ### define global convolutional lalyer\n",
        "        print('instantiating an ExtranetModel object')\n",
        "        self.fc_global = nn.Sequential(\n",
        "            nn.Conv1d(2, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(16, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(5, stride=2),\n",
        "            nn.Conv1d(16, 32, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 32, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(5, stride=2),\n",
        "            nn.Conv1d(32, 64, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 64, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(5, stride=2),\n",
        "            nn.Conv1d(64, 128, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, 128, 5, stride=1, padding=2),\n",
        "            nn.MaxPool1d(5, stride=2),\n",
        "            nn.Conv1d(128, 256, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, 256, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(5, stride=2),\n",
        "        )\n",
        "\n",
        "        ### define local convolutional lalyer\n",
        "        self.fc_local = nn.Sequential(\n",
        "            nn.Conv1d(2, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(16, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(7, stride=2),\n",
        "            nn.Conv1d(16, 32, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 32, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(7, stride=2),\n",
        "        )\n",
        "\n",
        "        ### define fully connected layer that combines both views\n",
        "        self.final_layer = nn.Sequential(\n",
        "            nn.Linear(16586, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            ### need output of 1 because using BCE for loss\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "        print('ExtranetModel object instantiated...')\n",
        "\n",
        "\n",
        "    def forward(self, x_local, x_global, x_local_cen, x_global_cen, x_star):\n",
        "\n",
        "        ### concatonate light curve and centroid data\n",
        "        x_local_all = torch.cat([x_local, x_local_cen], dim=1)\n",
        "        x_global_all = torch.cat([x_global, x_global_cen], dim=1)\n",
        "\n",
        "        ### get outputs of global and local convolutional layers\n",
        "        out_global = self.fc_global(x_global_all)\n",
        "        out_local = self.fc_local(x_local_all)\n",
        "\n",
        "        ### flattening outputs from convolutional layers into vector\n",
        "        out_global = out_global.view(out_global.shape[0], -1)\n",
        "        out_local = out_local.view(out_local.shape[0], -1)\n",
        "\n",
        "        ### concatonate global and local views with stellar parameters\n",
        "        out = torch.cat([out_global, out_local, x_star.squeeze(1)], dim=1)\n",
        "        out = self.final_layer(out)\n",
        "\n",
        "        return out\n",
        ""
      ],
      "metadata": {
        "id": "2vdlmroj0SVR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtranetXSModel(nn.Module):\n",
        "\n",
        "    '''\n",
        "\n",
        "    PURPOSE: DEFINE EXTRANET-XS MODEL ARCHITECTURE\n",
        "    INPUT: GLOBAL + LOCAL LIGHT CURVES AND CENTROID CURVES, STELLAR PARAMETERS\n",
        "    OUTPUT: BINARY CLASSIFIER\n",
        "\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        ### initializing the nn.Moduel (super) class\n",
        "        ### (must do this first always)\n",
        "        super(ExtranetXSModel, self).__init__()\n",
        "\n",
        "        ### define global convolutional lalyer\n",
        "        self.fc_global = nn.Sequential(\n",
        "            nn.Conv1d(2, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2),\n",
        "            nn.Conv1d(16, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2),\n",
        "            nn.Conv1d(16, 32, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        ### define the local convolutional layer\n",
        "        self.fc_local = nn.Sequential(\n",
        "            nn.Conv1d(2, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2, stride=2),\n",
        "            nn.Conv1d(16, 16, 5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        ### define fully connected layer that combines both views\n",
        "        self.final_layer = nn.Sequential(\n",
        "            nn.Linear(58, 1),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    ### define how to move forward through model\n",
        "    def forward(self, x_local, x_global, x_local_cen, x_global_cen, x_starpars):\n",
        "\n",
        "        ### concatonate light curve and centroid data\n",
        "        x_local_all = torch.cat([x_local, x_local_cen], dim=1)\n",
        "        x_global_all = torch.cat([x_global, x_global_cen], dim=1)\n",
        "        out_global = self.fc_global(x_global_all)\n",
        "        out_local = self.fc_local(x_local_all)\n",
        "\n",
        "        ### do global pooling\n",
        "        out_global = F.max_pool1d(out_global, out_global.shape[-1])\n",
        "        out_local = F.max_pool1d(out_local, out_local.shape[-1])\n",
        "\n",
        "        ### PATERSON EDIT do global pooling\n",
        "        # F is not defined, not sure what the authors were intending here\n",
        "\n",
        "        #out_global = max_pool1d(out_global, out_global.shape[-1])\n",
        "        #out_local = max_pool1d(out_local, out_local.shape[-1])\n",
        "\n",
        "        ### flattening outputs from convolutional layers into vector\n",
        "        out_global = out_global.view(out_global.shape[0], -1)\n",
        "        out_local = out_local.view(out_local.shape[0], -1)\n",
        "\n",
        "        ### concatonate global and local views with stellar parameters\n",
        "        out = torch.cat([out_global, out_local, x_starpars.squeeze(1)], dim=1)\n",
        "        out = self.final_layer(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "########################################\n",
        "########## DEFINE FUNCTIONS ############\n",
        "########################################\n",
        "\n",
        "def invert_tensor(tensor):\n",
        "\n",
        "    '''\n",
        "\n",
        "    PURPOSE: FLIP A 1D TENSOR ALONG ITS AXIS\n",
        "    INPUT: 1D TENSOR\n",
        "    OUTPUT: INVERTED 1D TENSOR\n",
        "\n",
        "    '''\n",
        "\n",
        "    idx = [i for i in range(tensor.size(0)-1, -1, -1)]\n",
        "    #idx = torch.cuda.LongTensor(idx)\n",
        "    idx = torch.LongTensor(idx)\n",
        "    inverted_tensor = tensor.index_select(0, idx)\n",
        "\n",
        "    return inverted_tensor\n",
        "\n",
        "\n",
        "def train_model(n_epochs, kepler_data_loader, kepler_val_loader, model, criterion, optimizer):\n",
        "\n",
        "    '''\n",
        "\n",
        "    PURPOSE: TRAIN MODEL\n",
        "\n",
        "    INPUTS:  num_epoch = number of epochs for training\n",
        "             kepler_data_loader = data loader for Kepler dataset\n",
        "             model = model use for training\n",
        "             criterion = criterion for calculating loss\n",
        "\n",
        "    OUTPUT:  epoch_{train/val}_loss = training set loss for each epoch\n",
        "             epoch_val_acc = validation set accuracy for each epoch\n",
        "             epoch_val_ap = validation set avg. precision for each epoch\n",
        "             final_val_pred = validation predictions from final model\n",
        "             final_val_gt = validation ground truths\n",
        "\n",
        "    '''\n",
        "\n",
        "    #print('Starting the train_model function')\n",
        "\n",
        "    ### empty arrays to fill per-epoch outputs\n",
        "    epoch_train_loss = []\n",
        "    epoch_val_loss = []\n",
        "    epoch_val_acc = []\n",
        "    epoch_val_ap = []\n",
        "\n",
        "    ### loop over number of epochs of training\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "\n",
        "        #print('\\nStarting the loop in tqdm\\n')\n",
        "        ####################\n",
        "        ### for training set\n",
        "\n",
        "        ### loop over batches\n",
        "        #train_loss = torch.zeros(1).cuda()\n",
        "        train_loss = torch.zeros(1)\n",
        "        #print('Stepping into the kepler_data_loader...this broke the jupyter')\n",
        "        import time\n",
        "        time.sleep(2)\n",
        "        #print('\\nHere goes...\\n')\n",
        "        for x_train_data, y_train in kepler_data_loader:\n",
        "\n",
        "            #print('We are passed the kepler_data_lader blocker and starting the pytorch...')\n",
        "\n",
        "            ### get local view, global view, and label for training\n",
        "            x_train_local, x_train_global, x_train_local_cen, x_train_global_cen, x_train_star = x_train_data\n",
        "            x_train_local = Variable(x_train_local).type(torch.FloatTensor).cpu() #.cuda()\n",
        "            x_train_global = Variable(x_train_global).type(torch.FloatTensor)#.cuda()\n",
        "            x_train_local_cen = Variable(x_train_local_cen).type(torch.FloatTensor)#.cuda()\n",
        "            x_train_global_cen = Variable(x_train_global_cen).type(torch.FloatTensor)#.cuda()\n",
        "            x_train_star = Variable(x_train_star).type(torch.FloatTensor)#.cuda()\n",
        "            y_train = Variable(y_train).type(torch.FloatTensor)#.cuda()\n",
        "\n",
        "\n",
        "            #print('completed the view splitting, on to inverting half of the light curves')\n",
        "            ### randomly invert half of light curves\n",
        "            for batch_ind in range(x_train_local.shape[0]):\n",
        "\n",
        "                ### add random gaussian noise\n",
        "                sig_noise = np.random.uniform(0, 1.0)\n",
        "                local_noise = Variable(x_train_local[batch_ind].data.new(x_train_local[batch_ind].size()).normal_(0.0, sig_noise))\n",
        "                x_train_local[batch_ind] = x_train_local[batch_ind] + local_noise\n",
        "                global_noise = Variable(x_train_global[batch_ind].data.new(x_train_global[batch_ind].size()).normal_(0.0, sig_noise))\n",
        "                x_train_global[batch_ind] = x_train_global[batch_ind] + global_noise\n",
        "\n",
        "                if random() < 0.5:\n",
        "                    x_train_local[batch_ind] = invert_tensor(x_train_local[batch_ind])\n",
        "                    x_train_global[batch_ind] = invert_tensor(x_train_global[batch_ind])\n",
        "                    x_train_local_cen[batch_ind] = invert_tensor(x_train_local_cen[batch_ind])\n",
        "                    x_train_global_cen[batch_ind] = invert_tensor(x_train_global_cen[batch_ind])\n",
        "\n",
        "            ### fix dimensions for next steps\n",
        "            x_train_local = x_train_local.unsqueeze(1)\n",
        "            x_train_global = x_train_global.unsqueeze(1)\n",
        "            x_train_local_cen = x_train_local_cen.unsqueeze(1)\n",
        "            x_train_global_cen = x_train_global_cen.unsqueeze(1)\n",
        "            x_train_star = x_train_star.unsqueeze(1)\n",
        "            y_train = y_train.unsqueeze(1)\n",
        "\n",
        "            ### calculate loss using model\n",
        "            output_train = model(x_train_local, x_train_global, x_train_local_cen, x_train_global_cen, x_train_star)\n",
        "            loss = criterion(output_train, y_train)\n",
        "            train_loss += loss.data\n",
        "\n",
        "            ### train model (zero gradients and back propogate results)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        ### record training loss for this epoch (divided by size of training dataset)\n",
        "        epoch_train_loss.append(train_loss.cpu().numpy() / len(kepler_data_loader.dataset))\n",
        "\n",
        "        ######################\n",
        "        ### for validation set\n",
        "\n",
        "        ### loop over batches\n",
        "        val_pred, val_gt, val_loss, num_corr = [], [], 0, 0\n",
        "        for x_val_data, y_val in kepler_val_loader:\n",
        "\n",
        "            ### get local view, global view, and label for validating\n",
        "            x_val_local, x_val_global, x_val_local_cen, x_val_global_cen, x_val_star = x_val_data\n",
        "            x_val_local = Variable(x_val_local).type(torch.FloatTensor)#.cuda()\n",
        "            x_val_global = Variable(x_val_global).type(torch.FloatTensor)#.cuda()\n",
        "            x_val_local_cen = Variable(x_val_local_cen).type(torch.FloatTensor)#.cuda()\n",
        "            x_val_global_cen = Variable(x_val_global_cen).type(torch.FloatTensor)#.cuda()\n",
        "            x_val_star = Variable(x_val_star).type(torch.FloatTensor)#.cuda()\n",
        "\n",
        "            ### fix dimensions for next steps\n",
        "            y_val = Variable(y_val).type(torch.FloatTensor)#.cuda()\n",
        "            x_val_local = x_val_local.unsqueeze(1)\n",
        "            x_val_global = x_val_global.unsqueeze(1)\n",
        "            x_val_local_cen = x_val_local_cen.unsqueeze(1)\n",
        "            x_val_global_cen = x_val_global_cen.unsqueeze(1)\n",
        "            x_val_star = x_val_star.unsqueeze(1)\n",
        "            y_val = y_val.unsqueeze(1)\n",
        "\n",
        "            ### calculate loss & add to sum over all batches\n",
        "            output_val = model(x_val_local, x_val_global, x_val_local_cen, x_val_global_cen, x_val_star)\n",
        "            loss_val = criterion(output_val, y_val)\n",
        "            val_loss += loss_val.data\n",
        "\n",
        "            ### get number of correct predictions using threshold=0.5\n",
        "            ### & sum over all batches\n",
        "            output_pred = output_val >= 0.5\n",
        "            num_corr += output_pred.eq(y_val.byte()).sum().item()\n",
        "\n",
        "            ### record predictions and ground truth by model\n",
        "            ### (used for AP per epoch; reset at each epoch; final values output)\n",
        "            val_pred.append(output_val.data.cpu().numpy())\n",
        "            val_gt.append(y_val.data.cpu().numpy())\n",
        "\n",
        "        ### record validation loss calculate for this epoch (divided by size of validation dataset)\n",
        "        epoch_val_loss.append(val_loss.cpu().numpy() / len(kepler_val_loader.dataset))\n",
        "\n",
        "        ### record validation accuracy (# correct predictions in val set) for this epoch\n",
        "        epoch_val_acc.append(num_corr / len(kepler_val_loader.dataset))\n",
        "\n",
        "        ### calculate average precision for this epoch\n",
        "        epoch_val_ap.append(average_precision_score(np.concatenate(val_gt).ravel(), np.concatenate(val_pred).ravel(), average=None))\n",
        "\n",
        "    ### grab final predictions and ground truths for validation set\n",
        "    final_val_pred = np.concatenate(val_pred).ravel()\n",
        "    final_val_gt = np.concatenate(val_gt).ravel()\n",
        "\n",
        "    return epoch_train_loss, epoch_val_loss, epoch_val_acc, epoch_val_ap, final_val_pred, final_val_gt"
      ],
      "metadata": {
        "id": "fSNL3-Qu0I_X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    print('Exonet.py was created by Dr. Megan Andsdell et al')\n",
        "    print('Starting exonet.py')\n",
        "    torch.set_default_device(\"cpu\")\n",
        "    ########################################\n",
        "    ########### PARSE ARGUMENTS ############\n",
        "    ########################################\n",
        "\n",
        "    ### an example input to command line:\n",
        "    ### python exonet.py 225 64 1e-5 '/data/kepler/new' '/data_sata1/ensembling/test'\n",
        "\n",
        "    ### parse arguments\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"n_epochs\", help=\"number of epochs to use for training\", type=int)\n",
        "    parser.add_argument(\"n_batches\", help=\"number of matches to use for training\", type=int)\n",
        "    parser.add_argument(\"r_learn\", help=\"learning rate for Adam optimizer\", type=float)\n",
        "    parser.add_argument(\"d_path\", help=\"path to data (should contain folders named val, test, train\")\n",
        "    parser.add_argument(\"m_out\", help=\"path for output model, files, and plots\")\n",
        "    parser.add_argument(\"--fixed_seed\", help=\"set if wanting to fix the seed\", action=\"store_true\")\n",
        "    parser.add_argument(\"--XS\", help=\"use Extranet model\", action=\"store_true\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    ### set manual seed\n",
        "    if args.fixed_seed:\n",
        "        torch.cuda.manual_seed(42)\n",
        "    ########################################\n",
        "    ############ TRAIN MODEL  ##############\n",
        "    ########################################\n",
        "\n",
        "    ### setup screen output\n",
        "    print(\"\\nTRAINING MODEL...\\n\")\n",
        "\n",
        "    ### initialize model; cuda puts it on GPU\n",
        "    if args.XS:\n",
        "        model = ExtranetXSModel().cuda()\n",
        "    else:\n",
        "        #model = ExtranetModel().cuda()\n",
        "        model = ExtranetModel()\n",
        "    ### learning rate\n",
        "    lr  = args.r_learn\n",
        "\n",
        "    ### specify optimizer for learning to use for training\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    ### specify loss function to use for training\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    ### specify batch size to use for training\n",
        "    batch_size = args.n_batches\n",
        "\n",
        "    ### number of epochs to use for training\n",
        "    n_epochs = args.n_epochs\n",
        "\n",
        "    ### grab data using data loader\n",
        "    kepler_train_data = KeplerDataLoader(filepath=os.path.join(args.d_path, 'train'))\n",
        "    kepler_val_data = KeplerDataLoader(filepath=os.path.join(args.d_path, 'test'))\n",
        "\n",
        "    ### setup data loaders for training and validation data\n",
        "    kepler_data_loader = DataLoader(kepler_train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    kepler_val_loader = DataLoader(kepler_val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    ### train model\n",
        "    loss_train_epoch, loss_val_epoch, acc_val_epoch, ap_val_epoch, pred_val_final, gt_val_final  = train_model(n_epochs, kepler_data_loader, kepler_val_loader, model, criterion, optimizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "2oYQDKYJz_Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ########################################\n",
        "    ####### CALCULATE STATISTICS ###########\n",
        "    ########################################\n",
        "\n",
        "    ### setup screen output\n",
        "    print(\"\\nCALCULATING METRICS...\\n\")\n",
        "\n",
        "    ### calculate average precision & precision-recall curves\n",
        "    AP = average_precision_score(gt_val_final, pred_val_final, average=None)\n",
        "    print(\"   average precision = {0:0.4f}\\n\".format(AP))\n",
        "\n",
        "    ### calculate precision-recall curve\n",
        "    P, R, _ = precision_recall_curve(gt_val_final, pred_val_final)\n",
        "\n",
        "    ### calculate confusion matrix based on different thresholds\n",
        "    thresh = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "    prec_thresh, recall_thresh = np.zeros(len(thresh)), np.zeros(len(thresh))\n",
        "    for n, nval in enumerate(thresh):\n",
        "        pred_byte = np.zeros(len(pred_val_final))\n",
        "        for i, val in enumerate(pred_val_final):\n",
        "            if val > nval:\n",
        "                pred_byte[i] = 1.0\n",
        "            else:\n",
        "                pred_byte[i] = 0.0\n",
        "        prec_thresh[n] = precision_score(gt_val_final, pred_byte)\n",
        "        recall_thresh[n] = recall_score(gt_val_final, pred_byte)\n",
        "        print(\"   thresh = {0:0.2f}, precision = {1:0.2f}, recall = {2:0.2f}\".format(thresh[n], prec_thresh[n], recall_thresh[n]))\n",
        "        tn, fp, fn, tp = confusion_matrix(gt_val_final, pred_byte).ravel()\n",
        "        print(\"      TN = {0:0}, FP = {1:0}, FN = {2:0}, TP = {3:0}\".format(tn, fp, fn, tp))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WrjifzT7zdXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "    ######### OUTPUT MODEL + STATS  ########\n",
        "    ########################################\n",
        "\n",
        "    ### transform from loss per sample to loss per batch (multiple by batch size to compare to Chris')\n",
        "    loss_train_batch = [x.item()* batch_size for x in loss_train_epoch]\n",
        "    loss_val_batch = [x.item()* batch_size for x in loss_val_epoch]\n",
        "\n",
        "    ### setup output\n",
        "    run = 0\n",
        "\n",
        "    ### output predictions & ground truth\n",
        "    pt_fname = os.path.join(args.m_out, 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-lr' + str(lr) + '-pt.csv')\n",
        "    while os.path.isfile(pt_fname):\n",
        "        run +=1\n",
        "        pt_fname = os.path.join(args.m_out, 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-lr' + str(lr) + '-pt.csv')\n",
        "    df = pd.DataFrame({\"gt\" : gt_val_final, \"pred\" : pred_val_final})\n",
        "    df.to_csv(pt_fname, index=False)\n",
        "\n",
        "    ### output per-iteration values\n",
        "    epochs_fname = os.path.join(args.m_out, 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-lr' + str(lr) + '-epoch.csv')\n",
        "    df = pd.DataFrame({\"loss_train\":loss_train_batch, \"loss_val\":loss_val_batch, \"acc_val\":acc_val_epoch, \"ap_val\":ap_val_epoch})\n",
        "    df.to_csv(epochs_fname, index=False)\n",
        "\n",
        "    ### save model\n",
        "    # the output path is joined twice with the output directory (possibly a bug)\n",
        "    #model_fname = os.path.join(args.m_out, 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-lr' + str(lr) + '-model.pth')\n",
        "    #torch.save(model.state_dict(), os.path.join(args.m_out, model_fname))\n",
        "    model_fname = 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-lr' + str(lr) + '-model.pth'\n",
        "    torch.save(model.state_dict(), os.path.join(args.m_out, model_fname))\n",
        "    print(\"\\nOUTPUTTING MODEL + RESULTS @ \" + os.path.join(args.m_out, model_fname) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "UN2boyJSzhYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    ########################################\n",
        "    ################ MAKE PLOTS ############\n",
        "    ########################################\n",
        "\n",
        "    ### setup figure\n",
        "    fig = plt.figure(figsize=(7, 7))\n",
        "    ax = gridspec.GridSpec(2,2)\n",
        "    ax.update(wspace = 0.4, hspace = 0.4)\n",
        "    ax1 = plt.subplot(ax[0,0])\n",
        "    ax2 = plt.subplot(ax[0,1])\n",
        "    ax3 = plt.subplot(ax[1,0])\n",
        "    ax4 = plt.subplot(ax[1,1])\n",
        "\n",
        "    ### plot precision-recall curve\n",
        "    ax1.set_xlabel('Precision', fontsize=10, labelpad=10)\n",
        "    ax1.set_ylabel('Recall', fontsize=10)\n",
        "    ax1.set_xlim([0.0, 1.0])\n",
        "    ax1.set_ylim([0.0, 1.0])\n",
        "    ax1.plot(R, P, linewidth=3, color='black')\n",
        "\n",
        "    ### plot loss curve for training and validation sets\n",
        "    ax2.set_xlabel('Epoch', fontsize=10, labelpad=10)\n",
        "    ax2.set_ylabel('Loss', fontsize=10)\n",
        "    ax2.set_xlim([0.0, n_epochs])\n",
        "    ax2.set_ylim([0.0, np.max(loss_train_batch)*1.5])\n",
        "    ax2.plot(np.arange(len(loss_train_batch)), loss_train_batch, linewidth=3, color='cadetblue')\n",
        "    ax2.plot(np.arange(len(loss_val_batch)), loss_val_batch, linewidth=3, color='orangered')\n",
        "\n",
        "    ### plot average precision per epoch\n",
        "    ax3.set_xlabel('Epoch', fontsize=10, labelpad=10)\n",
        "    ax3.set_ylabel('Average Precision', fontsize=10)\n",
        "    ax3.plot(np.arange(len(ap_val_epoch)), ap_val_epoch, linewidth=1.0, color='orangered')\n",
        "    ax3.scatter(np.arange(len(ap_val_epoch)), ap_val_epoch, marker='o', edgecolor='orangered', facecolor='orangered', s=10, linewidth=0.5, alpha=0.5)\n",
        "\n",
        "    ### plot accuracy per epoch\n",
        "    ax4.set_xlabel('Epoch', fontsize=10, labelpad=10)\n",
        "    ax4.set_ylabel('Accuracy', fontsize=10)\n",
        "    ax4.plot(np.arange(len(acc_val_epoch)), acc_val_epoch, color='orangered', linewidth=1.0)\n",
        "    ax4.scatter(np.arange(len(acc_val_epoch)), acc_val_epoch, marker='o', edgecolor='orangered', facecolor='orangered', s=10, linewidth=0.5, alpha=0.5)\n",
        "\n",
        "    ### save plot\n",
        "    plot_fname = 'r' + str(run).zfill(2) + '-i' + str(n_epochs) + '-plot.pdf'\n",
        "    plt.savefig(os.path.join(args.m_out, plot_fname), bbox_inches='tight', dpi=200, rastersized=True, alpha=True)"
      ],
      "metadata": {
        "id": "B9AIZk5czhwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}